{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7cfd31",
   "metadata": {},
   "source": [
    "# CH5019: Mathematical Foundations of Data Science\n",
    "## *Course Project*\n",
    "## Group-6\n",
    "In this notebook we examine the task of automatically grading answers to descriptive questions. Often exams have comprehensive questions, but manually accessing and grading the answer is not trivial. The purpose of this exercise is to grade students answer by automatically retrieving the closest sample answer and grdaing accordingly.\n",
    "\n",
    "**Our basic strategy is as follows**\n",
    "\n",
    "We already have the template best answer to each question. Also, we have generated 5 sample answers from the template best answer & assigned marks out of 10 to each sample answer. For the asked question, we have to find the sample answer closest in meaning to the students answer & display marks gained by student for that particular question according to the retrieved sample answer. \n",
    "\n",
    "To compare two answer scripts we need to have an efficient way of computing semantic similarity between two sentences. To compute semantic similarity between sentences, we will convert each sentence into a vector. We can then use cosine similarity between vectors to come up with a distance measure between sentences that indicates how similar they are in meaning. This is an implementation of natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5d3c6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim \n",
    "from gensim.parsing.preprocessing import remove_stopwords \n",
    "import gensim.downloader as api\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity;\n",
    "\n",
    "# Loading the Q&A data set\n",
    "df = pd.read_csv(\"Data/DS_interview.csv\");\n",
    "\n",
    "# Renaming columns of data set\n",
    "df.columns = [\"Q.No\", \"questions\",\"answers\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "69bb1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------Question & Answer pairs------------------------------------------------\n",
      "\n",
      "\u001b[1mQuestion 1 : What is Data Science?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Data Science is a combination of algorithms, tools, and machine learning techniques which helps you to find common hidden patterns from the given raw data.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 2 : What is Logistic Regression?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Logistic Regression is a method to forecast the binary outcome from a linear combination of predictor variables using sigmoid function.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 3 : What is Bias?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Bias is an error introduced in your model because of the oversimplification of a machine learning algorithm.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 4 : Define Boltzmann Machine?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Boltzmann machines is a simple learning algorithm, which helps you to discover features that represent complex regularities in the training data.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 5 : What is the K-means clustering method?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: K-means clustering is an unsupervised learning technique of classifying data using K set of clusters.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 6 : Explain Collaborative filtering?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Collaborative filtering is used to search for correct patterns by collaborating viewpoints, multiple data sources, and various agents.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 7 : Explain Eigenvectors?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: An eigenvector of a linear transformation is a nonzero vector that changes at most by a scalar factor when that linear transformation is applied to it.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 8 : What is skewed Distribution & uniform distribution?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Skewed distribution occurs when if data is distributed on any one side of the plot whereas uniform distribution is identified when the data is spread is equal in the range.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 9 : When does under-fitting occur in a static model?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Under-fitting occurs when a statistical model or machine learning algorithm not able to capture the underlying trend of the data.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mQuestion 10 :  Define the term deep learning?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Deep Learning is a subtype of machine learning which is concerned with algorithms inspired by the structure called artificial neural networks.\u001b[0;0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question & answer data set\n",
    "print(\"--------------------------------------------Question & Answer pairs------------------------------------------------\\n\")\n",
    "for i in range(1,11):\n",
    "    Ques = df.loc[df[\"Q.No\"]== i]\n",
    "    print('\\033[1m' + \"Question\",i,\":\",Ques[\"questions\"].iloc[0] + \"\\033[0;0m\")\n",
    "    print('\\033[1m' + \"\\nStandard Answer:\",Ques[\"answers\"].iloc[0] + \"\\033[0;0m\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "06f702cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to choose question-answer pair from given data set\n",
    "def Q_selection(Q):\n",
    "    # Loop to change input, if not in given range\n",
    "    while(True):\n",
    "        Question_Number = input(\"Enter the question number you want to ask from above the list of questions:\")\n",
    "        Q = int(Question_Number)\n",
    "        \n",
    "        # Error message\n",
    "        if Q > 10 or Q < 1:\n",
    "            print('\\033[1m' + \"Error: Please enter a number from 1 to 10\\n\"+ \"\\033[0;0m\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(\"\\n---------------------You have selected following Q&A pair:-----------------\\n\")\n",
    "        \n",
    "    Ques = df.loc[df[\"Q.No\"]== Q]\n",
    "    print('\\033[1m' + \"Question:\",Ques[\"questions\"].iloc[0] + \"\\033[0;0m\")\n",
    "    print('\\033[1m' + \"\\nStandard Answer:\",Ques[\"answers\"].iloc[0] + \"\\033[0;0m\")\n",
    "        \n",
    "    return Q    # Return the choosen question number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "30235cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the question number you want to ask from above the list of questions:3\n",
      "\n",
      "---------------------You have selected following Q&A pair:-----------------\n",
      "\n",
      "\u001b[1mQuestion: What is Bias?\u001b[0;0m\n",
      "\u001b[1m\n",
      "Standard Answer: Bias is an error introduced in your model because of the oversimplification of a machine learning algorithm.\u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "# Choosing question-answer pair number\n",
    "N = Q_selection(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d7e12cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the sample answers data set for the choosen Q&A pair, N\n",
    "sample = pd.read_csv(('Data/Sample_'+str(N)+'.csv'));\n",
    "\n",
    "# Renaming columns of sample answers data set\n",
    "sample.columns=[\"marks\",\"answers\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a406705",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "\n",
    "Most NLP tasks involve preprocessing. For this task we are performing the following preprocessing : \n",
    "1. Removing all characters that are not alpha numeric\n",
    "2. Removing stopwords - commonly used words such as 'a', 'to', 'in' and so on.. that do not contribute to the semantic similarity between two sentences.\n",
    "\n",
    "We apply this to both the sample answers and the students answer sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6f89b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning single sentence\n",
    "def clean_sentence(sentence, stopwords = False):\n",
    "    # Converting all characters to lower case\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # Replace non-alpha numeric characters with spaces\n",
    "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "    \n",
    "    # Removing stopwords if asked to do so\n",
    "    if stopwords:\n",
    "         sentence = remove_stopwords(sentence)\n",
    "    \n",
    "    # Returning cleaned sentence\n",
    "    return sentence\n",
    "            \n",
    "# Cleaning data frame of sentences\n",
    "def get_cleaned_sentences(df,stopwords = False):\n",
    "    # Choosing answers column from data frame\n",
    "    sents = df[[\"answers\"]];\n",
    "    cleaned_sentences=[]   # Initializing list to store cleaned sentences\n",
    "\n",
    "    # Looping over rows of data frame\n",
    "    for index,row in df.iterrows():\n",
    "        # Cleaning each sentence\n",
    "        cleaned = clean_sentence(row[\"answers\"],stopwords);\n",
    "        \n",
    "        # Appending cleaned sentence to the cleaned_sentences list\n",
    "        cleaned_sentences.append(cleaned);\n",
    "    \n",
    "    # Returning data frame of cleaned sentences\n",
    "    return cleaned_sentences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7192ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning all sample answers of the choosen Q&A pair\n",
    "cleaned_sample_ans = get_cleaned_sentences(sample, stopwords = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5409d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take students answer of asked question as input\n",
    "def student_answer():\n",
    "    student_ans = input(\"---------Student should type his answer below and press enter---------\\n\")\n",
    "    \n",
    "    # Cleaning students answer\n",
    "    student_ans = clean_sentence(student_ans, stopwords = True);\n",
    "    \n",
    "    # Returning cleaned student answer\n",
    "    return student_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "184e2efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Student should type his answer below and press enter---------\n",
      "Bias is an error introduced in your model because of the oversimplification of a machine learning algorithm.\n"
     ]
    }
   ],
   "source": [
    "# Reading & cleaning students answer\n",
    "cleaned_student_ans = student_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3fcca",
   "metadata": {},
   "source": [
    "# Glove Embeddings\n",
    "\n",
    "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. Deatil information about Glove Embeddings can be found in below link\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9fdea08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded glove model\n"
     ]
    }
   ],
   "source": [
    "# Making glove embedding model\n",
    "glove_model = None;   # Initialization\n",
    "\n",
    "# Checking if model is already downloaded\n",
    "try:\n",
    "    glove_model = gensim.models.KeyedVectors.load(\"./glovemodel.mod\")\n",
    "    print(\"Loaded glove model\")\n",
    "    \n",
    "# Download the model if not already downloaded\n",
    "except:            \n",
    "    glove_model = api.load('glove-twitter-25')\n",
    "    glove_model.save(\"./glovemodel.mod\")\n",
    "    print(\"Saved glove model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6c1b3",
   "metadata": {},
   "source": [
    "**Finding Phrase Embeddings from Word Embeddings** \n",
    "\n",
    "Simplest technique to convert word embeddings to phrase embeddings, that is applicable with glove embeddings, is to sum up the individual word embeddings in the phrase to get a phrase vector. It is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bcf0715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert word to vector by given model\n",
    "def getWordVec(word, model):\n",
    "    # Reading downloaded model from computer\n",
    "    samp = model['computer'];\n",
    "    \n",
    "    # Initializing vector\n",
    "    vec = [0]*len(samp);\n",
    "    \n",
    "    # Checking if word is already present in model\n",
    "    try:\n",
    "            vec = model[word];\n",
    "    except:\n",
    "            vec = [0]*len(samp);\n",
    "    \n",
    "    # Returning the word vector\n",
    "    return vec\n",
    "\n",
    "# Function to convert word embeddings to phrase embeddings\n",
    "def getPhraseEmbedding(phrase, embeddingmodel):\n",
    "\n",
    "        samp = getWordVec('computer', embeddingmodel);\n",
    "        vec = np.array([0]*len(samp));\n",
    "        den = 0;\n",
    "        \n",
    "        # Looping over all words of given phrase\n",
    "        for word in phrase.split():\n",
    "            den = den + 1;\n",
    "            vec = vec + np.array(getWordVec(word,embeddingmodel));\n",
    "            \n",
    "        # Returning the phrase embedding\n",
    "        return vec.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5b4d5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to displaying cosine similaritiy & final marks obtained\n",
    "def retrieveAndPrintmarks(student_embedding, sample_embedding, sample_df):\n",
    "    print(\"Cosine similarity between students answer & each sample answer for Q\"+str(N)+\" are as follows:\\n\")\n",
    "    \n",
    "    max_sim = -1;   # Initializing maximum value of cosine similarity\n",
    "    index_sim = -1;  # Initializing index corresponding to maximum cosine similarity\n",
    "    \n",
    "    # Looping over all sample embeddings\n",
    "    for index, samp_embedding in enumerate(sample_embedding):\n",
    "        \n",
    "        # Computing cosine similarity between student answer & sample answer\n",
    "        sim = cosine_similarity(samp_embedding, student_embedding)[0][0];\n",
    "        \n",
    "        # Displaying cosine similarity for each sample answer\n",
    "        print('\\033[1m' + \"Sample answer\", index + 1, \"(\" + str(10 - index*2) + \"/10):\", sim,\"\\033[0;0m\")\n",
    "        \n",
    "        # Changing the maximum value of cosine similarity & corresponding index in sample_df\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim;\n",
    "            index_sim = index;\n",
    "    \n",
    "    # Computing & displaying student mark\n",
    "    value = sample_df.iloc[index_sim,0] * max_sim\n",
    "    print('\\033[1m', \"\\nStudent Marks out of 10: \",\"{:.2f}\".format(value),\"\\033[0;0m\")\n",
    "    \n",
    "    # Displying formula to compute student mark\n",
    "    print(\"\\nNote: Formula used for marks calculation is as follows\")\n",
    "    print(\"\\tMarks = (Marks of retrieved sample answer)*(Corresponding cosine similairty)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ab1122ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between students answer & each sample answer for Q3 are as follows:\n",
      "\n",
      "\u001b[1mSample answer 1 (10/10): 0.9999999999999999 \u001b[0;0m\n",
      "\u001b[1mSample answer 2 (8/10): 0.9890437788074244 \u001b[0;0m\n",
      "\u001b[1mSample answer 3 (6/10): 0.9768594868947094 \u001b[0;0m\n",
      "\u001b[1mSample answer 4 (4/10): 0.9706787154068517 \u001b[0;0m\n",
      "\u001b[1mSample answer 5 (2/10): 0.8837214519016757 \u001b[0;0m\n",
      "\u001b[1m \n",
      "Student Marks out of 10:  10.00 \u001b[0;0m\n",
      "\n",
      "Note: Formula used for marks calculation is as follows\n",
      "\tMarks = (Marks of retrieved sample answer)*(Corresponding cosine similairty)\n"
     ]
    }
   ],
   "source": [
    "# Applying Glove embedding model\n",
    "sample_embeddings = [];   # Initializing list of sample answer embeddings\n",
    "\n",
    "# Looping over sample answers\n",
    "for sent in cleaned_sample_ans:\n",
    "    # Computing & appending each sample answer embedding to sample_embeddings using Glove model\n",
    "    sample_embeddings.append(getPhraseEmbedding(sent, glove_model));\n",
    "\n",
    "# Computing student answer embedding using Glove model\n",
    "student_embedding = getPhraseEmbedding(cleaned_student_ans, glove_model);\n",
    "\n",
    "# Displaying final results\n",
    "retrieveAndPrintmarks(student_embedding, sample_embeddings, sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fc5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
